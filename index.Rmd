---
title: "Open Case Studies : Disparities in Youth Disconnection"
css: style.css
output:
  html_document:
    self_contained: yes
    code_download: yes
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes

---

<style>
#TOC {
  background: url("https://opencasestudies.github.io/img/logo.jpg");
  background-size: contain;
  padding-top: 240px !important;
  background-repeat: no-repeat;
}
</style>







<style>
div.red { background-color:#ffcccb; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**MICHAEL ONTIVEROS**

*There are some existing typos in the tables in addition to those produced during the use of Magick. I made some assumptions along the way, documenting them. These need to be checked for accuracy.*
</div>

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE, cache = FALSE,
                      fig.align = "center", out.width = '90%')
library(here)
library(knitr)
```


#### {.outline }
```{r, echo = FALSE, out.width = "800 px", eval=FALSE}
knitr::include_graphics(here::here("img", "mainplot.png"))
```

####

## {.disclaimer_block}

**Disclaimer**: The purpose of the [Open Case Studies](https://opencasestudies.github.io){target="_blank"} project is **to demonstrate the use of various data science methods, tools, and software in the context of messy, real-world data**. A given case study does not cover all aspects of the research process, is not claiming to be the most appropriate way to analyze a given data set, and should not be used in the context of making policy decisions without external consultation from scientific experts. 


## {.license_block}

This work is licensed under the Creative Commons Attribution-NonCommercial 3.0 [(CC BY-NC 3.0)](https://creativecommons.org/licenses/by-nc/3.0/us/){target="_blank"}  United States License.


## {.reference_block}

To cite this case study please use:

Wright, Carrie, and Ontiveros, Michael and Jager, Leah and Taub, Margaret and Hicks, Stephanie. (2020). https://github.com/opencasestudies/ocs-youth-disconnection-case-study. Disparities in Youth Disconnection (Version v1.0.0).

## **Motivation**
*** 

According to this [report](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf) youth disconnection although generally showing decreasing trends for the past 7 years, shows racial and ethnic disparities, where some groups are showing increased rates of disconnection.

So what deos the term **"youth disconnection"** mean?

According to [Measure of America](https://www.ssrc.org/programs/view/moa/){target="_blank"} (a nonpartisan project of the nonprofit [Social Science Research Council](https://www.ssrc.org/){target="_blank"} that is focused on opportunity in the United States) disconnected youth are:

> "young people between the ages of **16 and 24** who are **neither working nor in school**"

They state that such disconnection hinders these individuals to aquire skills and create relationships necessary to have a sucessful adulthood. 

They state that:

> "people who experience a period of disconnection as young adults go on to **earn less** and are **less likely** to be **employed, own a home, or report good health** by the time they reach their thirties"

We will expand beyond the [Measure of America annual report](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf){target="_blank"} to create visualizations of percent disconnection of more specific groups of youths (gender, ethnic groups etc.) graphed together over time to allow for easier comparison.

https://onlinelibrary.wiley.com/doi/full/10.1111/1468-0009.12425



## **Main Questions**
*** 

#### {.main_question_block}
<b><u> Our main question: </u></b>

1) What differences in youth disconnection rates exist in 2017?  


How have youth disconnection rates in American youth changed since 2008? In particular, how has this changed for different states, gender, and ethnic groups? Are any groups particularly disconnected?

####

## **Learning Objectives** 
*** 

In this case study, we will demonstrate how to import and wrangle data available in the <u>**P**</u>ortable <u>**D**</u>ocument <u>**F**</u>ormat (**PDF**). We will especially focus on using packages and functions from the [`Tidyverse`](https://www.tidyverse.org/){target="_blank"}, such as `dplyr`, `ggplot2`. The tidyverse is a library of packages created by RStudio. While some students may be familiar with previous R programming packages, these packages make data science in R especially efficient.

The skills, methods, and concepts that students will be familiar with by the end of this case study are:

Data science skills:

1. Importing data from PDF files using the `magick` package
2. Apply action verbs in `dplyr` for data wrangling
3. How to pivot between "long" and "wide" datasets
4. Joining together multiple datasets using `dplyr`
5. How to create data visualizations with `ggplot2` that are in a similar style to an existing image

Statistical concepts and methods:



```{r, out.width = "20%", echo = FALSE, fig.align ="center"}
include_graphics("https://tidyverse.tidyverse.org/logo.png")
```

*** 

We will begin by loading the packages that we will need:

```{r}
library(here)
library(tidyverse)
library(pdftools)
library(magick)
library(cowplot)
library(Kendall)
```

<style>
div.green { background-color:#90EE90; border-radius: 5px; padding: 20px;}
</style>
<div class = "green">
**MICHAEL ONTIVEROS** *I changed the way the table looks below to present the package names in bold. Many of these case studies have lots of text. Having important features of a case study presented in bold, italics, or both may make the document more easily interpretable. This is just my two &cent;. Feel free to disregard this suggestion for any reason.*
</div>

 Package   | Use                                                                         
---------- |-------------
[**here**](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data
[**tidyverse**](https://readr.tidyverse.org/){target="_blank"}      | for data science operations
[**pdftools**](https://readr.tidyverse.org/){target="_blank"}      | to manage PDF documents
[**magick**](https://cran.r-project.org/web/packages/magick/vignettes/intro.html#Kernel_convolution){target="_blank"}      | for image processing 

The first time we use a function, we will use the `::` to indicate which package we are using. Unless we have overlapping function names, this is not necessary, but we will include it here to be informative about where the functions we will use come from.

## **Context**
*** 

```{r, echo = FALSE, out.width = "800 px"}
knitr::include_graphics(here::here("img", "risk_factors.png"))
```
##### [[source]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6243446/pdf/10.1177_0033354918799344.pdf){target="_blank"} 


## **Limitations**
*** 

<style>
div.green { background-color:#90EE90; border-radius: 5px; padding: 20px;}
</style>
<div class = "green">

**MICHAEL ONTIVEROS**

*I compared the mechanics of image processing tools to a black box process. I feel it brings in some vocab while highlighting that this type of tool requires caution. Feel free to update as you think appropriate.*
</div>

There are some important considerations regarding this data analysis to keep in mind: 

1) The statistical procedures we are using may be overly simplistic. *We need to be wary about deriving meaning from the statistical procedures we use*. 

2) Using image processing tools can be very helpful. The manner in which data is obtained with image processing tools is what we would describe as a **black box process**, <u>*a process with known inputs and outputs but unknown mechanics*</u>. Because we are unaware of how our outputs are generate from our inputs, we need to be wary of the output. With the small output we are creating in this case study, a visual inspection should suffice. 

## **What are the data?**
*** 

In this case study we will be using data related to youth disconnection from the two following reports from the [Measure of America](https://www.ssrc.org/programs/view/moa/){target="_blank"}  project:

> Measure of America is a nonpartisan project of the nonprofit [Social Science Research Council](https://www.ssrc.org/){target="_blank"}  founded in 2007 to create easy-to-use yet methodologically sound tools for understanding well-being and opportunity in America. Through reports, interactive apps, and custom-built dashboards, Measure of America works with partners to breathe life into numbers, using data to identify areas of highest need, pinpoint levers for change, and track progress over time.

1. Lewis, Kristen. [Making the Connection: Transportation and Youth Disconnection](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf){target="_blank"} . New York: Measure of America, Social Science Research Council, 2019.  (Data up to 2017)
2. : Lewis, Kristen. [A Decade Undone: Youth Disconnection in the Age of Coronavirus](https://ssrc-static.s3.amazonaws.com/moa/ADecadeUndone.pdf){target="_blank"} .
New York: Measure of America, Social Science Research Council, 2020. (Data up to 2018)


## **Data Import**
*** 

One way to import data from a pdf is to use the  `pdftools` packages. 

From the output, it's clear that a large amount of manipulation will be required to wrangle this data with the `pdftools` package.

#### {.scrollable }
```{r}
pdf_data_example <- pdftools::pdf_data(here("docs", "Making_the_Connection.pdf"))

utils::head(pdf_data_example, 1)

pdf_tools_example <- pdftools::pdf_text(here("docs","Making_the_Connection.pdf"))

head(pdf_tools_example, 1)
```
####

While not impossible, it's hard not to argue that using the `pdftools` package in this scenario will require a lot of advanced data wrangling. While our output may be reproducible, the amount of time to achieve this reproducibility may not be any more efficient than typing the table by hand into a text or spreadsheet program.

Fortunately, there is another way we can proceed to wrangle the data. 

We will demonstrate how to produce reproducible tables with image processing software in `R`. 

For demonstrative purposes, we will import two sets of data. The first set of data will be used to highlight common errors that the image processing software may produce. The second set of data will be used to demonstrate how to circumvent these errors and produce reproducible datasets efficiently.

We will now import the data using the `magick` and `here` packages. 

```{r, dpi = 1000}
#bold is causing issues
image_example <- magick::image_read(here::here("img", "gender_race_ethnicity.png"))

magick::image_info(image_example)
```

We import the same data—this time without regions of the table without special formatting—using the `magick` and `here` packages. 

```{r, dpi = 1000}
#bold is causing issues
image1 <- image_read(here("img", "gender_race_ethnicity2.png"))

magick::image_info(image1)
```

## **Data Exploration and Wrangling**
*** 

The first image we imported looks like this. 

```{r}
image_example
```

Parts of the table depicted in the image above contain [**newline**](https://en.wikipedia.org/wiki/Newline?oldformat=true) characters. A newline character denotes the end of a line of text and the start of a new line of text. 

This makes it more difficult to wrangle this table. Wrangling the data via regular expressions may be very tedious. It's unlikely that image processing software can handle the newline characters—or any other special characters—correctly.

Using `image_ocr()` by `magick` on the image above will render some errors in the first few lines. 

```{r}
df1 <- magick::image_ocr(image_example)

df1 %>%
  base::strsplit("\n") %>%
  base::unlist() %>%
  tibble::as_tibble()
```

If we remove these lines, some new errors emerge. 

```{r}
df1 %>%
    base::strsplit("\n") %>%
  base::unlist() %>%
  tibble::as_tibble() %>%
  dplyr::slice(-(1:3))
```

Data wrangling is not an exact science. The approaches we can take are extremely dependent on the data. We can exploit patterns in the data to render the output we desire. 

We will now use a cropped version of the image above without the special formatting.

#### {.scrollable }
```{r, dpi = 1000}
rm(df1)

image_info(image1)

base::print(image1)

df1 <- image_ocr(image1)

df1 <- df1 %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()
```
####

We have several strings. Each cell of data is on a string separated by space. 

We separate each string by space. 

```{r}
df1 <- df1 %>%
  dplyr::select(value) %>%
  pull(value) %>%
  str_split(" ")
```

We split the dataframe in two: a labels section and a "data" section containing the information we are interested in. 

In the first half, we remove all digits and punctuation to ensure that we are left with character labels.

In the second-half, remove commas and periods, converting the resulting string character class to numeric and selectively multiplying columns to reintroduce the decimal point correctly 

```{r}
df1a <- df1 %>%
  purrr::map(~base::paste(.,collapse = "")) %>%
  purrr::map(~base::gsub("[[:digit:]]+|[[:punct:]]+", "",.)) %>%
  base::do.call(base::rbind,.) %>%
  base::data.frame() %>%
  dplyr::tibble()

df1b <- map(df1, tail, 8) %>%
  map(~gsub("[,]+|[.]+", "",.)) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  dplyr::mutate_if(base::is.character, base::as.numeric) %>%
  dplyr::mutate_at(vars(-X7), ~ . * 0.1) %>%
  tibble() 

base::rm(df1)
```

We combine the two sections of data to create our dataframe, removing and then adding column names.

```{r}
df1 <- dplyr::bind_cols(df1a,
                        df1b)

base::names(df1) <- c()

column_names <- c("Group",
                  "Perc_2008",
                  "Perc_2010",
                  "Perc_2012",
                  "Perc_2014",
                  "Perc_2016",
                  "Perc_2017",
                  "N_2017",
                  "Delta_perc")

base::colnames(df1) <- column_names
```

We remove columns with information we don't need and use the commmon pattern in the column names to convert the data into [long/narrow format](https://en.wikipedia.org/wiki/Wide_and_narrow_data?oldformat=true).

```{r}
df1 <- df1 %>%
  dplyr::select(-N_2017,
                -Delta_perc)

df1 <- df1 %>%
  tidyr::pivot_longer(cols=contains("Perc_"),
                      names_to = "Year",
                      values_to = "Rate",
                      names_prefix = "Perc_") %>%
  dplyr::mutate(Year = as.numeric(Year))
```

We use the `dplyr::case_when()` and `stringr::str_detect()` function to detect patterns and create an separate column with gender and race information.

The two columns created contain `TRUE/FALSE` statements. These are then used to create a third column that will allow us to separate the data by its summary level. 

```{r}
df1 <- df1 %>%
  mutate(Gender = dplyr::case_when(stringr::str_detect(Group, "Female") ~ TRUE,
                            stringr::str_detect(Group, "Male") ~ FALSE,
                            TRUE ~ NA),
         Race = stringr::str_remove_all(Group,
                               pattern = paste(c("Female","Male","UnitedStates"),
                                               collapse = "|"))) %>%
  mutate(Race = dplyr::na_if(Race, ""))

df1 <- df1 %>% 
  mutate(Type = case_when(base::is.na(Gender) & base::is.na(Race) ~ "US Total",
                          base::is.na(Gender) & !base::is.na(Race) ~ "Race Total",
                          !base::is.na(Gender) & base::is.na(Race) ~ "Gender Total",
                          TRUE ~ "Subgroup Total"))

df1 <- df1 %>%
  mutate(Gender = case_when(str_detect(Group, "Female") ~ "Female",
                            str_detect(Group, "Male") ~ "Male"))
```

The columns of `character` class currently contain upper and lower case characters. We want to ensure that we use a cases consistently to ensure that there are no errors driven by case-sensitive function downstream.

To do this, we use the `base::to_upper()` function. This function makes all characters uppercase.

```{r}
df1 <- df1 %>% 
  mutate_if(is.character, toupper)
```

Finally, we homogenize the labels assigned for certain groups, fill in missing (`NA`) values with a string, and remove columns we no longer need from the dataframe. 

```{r}
df1 <- df1 %>%
  mutate(Race = case_when(Race == "LATINA" ~ "LATINO/A",
                          Race == "LATINO" ~ "LATINO/A",
                          Race == "NATIVEAMERICAN" ~ "NATIVE AMERICAN",
                          TRUE ~ Race)) %>%
  mutate(Gender = tidyr::replace_na(Gender, "ALL"),
         Race = tidyr::replace_na(Race, "ALL")) %>%
  dplyr::select(-Group)
```

We can repeat this process for the other two tables listed on page 39.

Let's look at the table without the special formatting.

```{r}
image2 <- image_read(here("img", "asian_subgroups.png"))
image2
```

As you can see, there are empty spaces. According to the PDF, these spaces are empty to denote that the estimates are unreliable.

This may cause problems. Whitespace must be handled differently. We may not want to process the entire image for this reason. 

Instead, we can use separate images to ensure a simpler process like that above. 

We read the three images. 
```{r}
image2a <- image_read(here("img", "asian_subgroupsA.png"))
image2b <- image_read(here("img", "asian_subgroupsB.png"))
image2c <- image_read(here("img", "asian_subgroupsC.png"))

magick::image_info(image2a)
magick::image_info(image2b)
magick::image_info(image2c)
```

The images look like this.

```{r}
image2a
image2b
image2c
```

We save the text from the images into objects.

```{r}
df2a <- magick::image_ocr(image2a)
df2b <- magick::image_ocr(image2b)
df2c <- magick::image_ocr(image2c)
```

We process these objects separately. Note that we use a very similar process to that employed in the wrangling of the previous table. 

```{r}
df2a <- df2a %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()

df2b <- df2b %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()

df2c <- df2c %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()
```

We then combine the objects with the `dplyr::bind_rows()` function.

The process is now very similar to the previous table.

<style>
div.red { background-color:#ffcccb; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**MICHAEL ONTIVEROS**

*I used base R to remove the first three rows of a dataframe in the following chunk. I am not aware of a tidyverse solution for this; I am sure one exists.*
</div>

```{r}
df2 <- bind_rows(df2a,
          df2b,
          df2c)

df2 <- df2 %>%
  dplyr::select(value) %>%
  pull(value) %>%
  str_split(" ")

df2b <- map(df2, tail, 2) %>%
  map(~gsub("[,]+|[.]+", "",.)) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  mutate_if(is.character, as.numeric) %>%
  mutate_at(vars(-X2), ~ . * 0.1) %>%
  tibble() 

df2a <- df2 %>%
  map(~paste(.,collapse = "")) %>%
  map(~gsub("[[:digit:]]+|[[:punct:]]+", "",.)) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  tibble()

df2 <- bind_cols(df2a, df2b)

names(df2) <- c()

column_names <- c("Group",
                  "Rate",
                  "N_2017")

colnames(df2) <- column_names

df2 <- df2 %>%
  dplyr::select(-N_2017)

df2 <- df2 %>%
  dplyr::mutate(Year = 2017)

df2 <- df2 %>%
  mutate(Gender = case_when(str_detect(Group, "Female") ~ TRUE,
                            str_detect(Group, "Male") ~ FALSE,
                            TRUE ~ NA),
         Subgroup = str_remove_all(Group,
                                   pattern = paste(c("Female",
                                                     "Male",
                                                     "ASIAN",
                                                     "Asian"),
                                               collapse = "|"))) %>%
  mutate(Subgroup = na_if(Subgroup, ""))

glimpse(df2)

df2 <- df2[-(1:3),]

df2 <- df2 %>% 
  mutate(Type = case_when(is.na(Gender) & is.na(Subgroup) ~ "Asian Total",
                          is.na(Gender) & !is.na(Subgroup) ~ "Subgroup Total",
                          !is.na(Gender) & is.na(Subgroup) ~ "Gender Total",
                          TRUE ~ "Subgroup Total"))

glimpse(df2)

df2 <- df2 %>%
  mutate(Gender = case_when(str_detect(Group, "Female") ~ "Female",
                            str_detect(Group, "Male") ~ "Male"))

df2 <- df2 %>% 
  mutate_if(is.character, tolower) %>%
  mutate_if(is.character, toupper)

df2 <- df2 %>%
  mutate(Gender = replace_na(Gender, "ALL"),
         Subgroup = replace_na(Subgroup, "ALL")) %>%
  dplyr::select(-Group) %>%
  mutate(Subgroup)

df2 <- df2 %>%
  mutate(Subgroup = case_when(Subgroup == "TWOORMORE" ~ "TWO OR MORE",
                              TRUE ~ Subgroup))
```

Note that we took a process that had successfully worked for us and modified it slightly for separate, similarly-sourced data. 

This is a common approach in data science. Often, the duration of the wrangling process can limit the depth of an analysis for practical reasons. Using tried methods can help reduce the time needed to wrangle data and allow time for other parts of an analysis. 

Let's add the 2018 data for this group.

We import the image. 

```{r}
image5 <- image_read(here("img", "asian_subgroups_2018.png"))

df2_2018 <- magick::image_ocr(image5)
```

As you can see, we have repeated newlines (`\n`). We can remove these with some simplex regex.

```{r}
df2_2018 <- gsub('([\n])\\1+',
                 '\\1',
                 df2_2018)

df2_2018 <- gsub("[[:punct:]]+",
                 "",
                 df2_2018)

df2_2018 <- gsub(" i ",
                 "",
                 df2_2018)
```

We proceed, making slight modifications to the process as needed.

The bold font appears to have caused a typos. 

```{r}
df2_2018 %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()
```

We fix the typos.

```{r}
df2_2018 <- df2_2018 %>%
  strsplit("\n") %>%
  unlist() %>%
  gsub(" B44 ","54",.) %>%
  gsub("Women74","Women 74",.) %>%
  gsub("HMONG102","HMONG 102",.) %>%
  as_tibble()

df2_2018 %>%
  print(.,n = dim(.)[1])
```

We then continue as we would normally. 

```{r}
df2_2018 <- df2_2018 %>%
  dplyr::select(value) %>%
  pull(value) %>%
  str_split(" ")

df2_2018 <- lapply(df2_2018,
                   function(x) x[nchar(x) >= 1])

df2a_2018 <- df2_2018 %>%
  map(~paste(.,collapse = "")) %>%
  map(~gsub("[[:digit:]]+|[[:punct:]]+", "",.)) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  tibble()

df2b_2018 <- map(df2_2018, tail, 2) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  mutate_if(is.character, as.numeric) %>%
  mutate_at(vars(-X2), ~ . * 0.1) %>%
  tibble() 

rm(df2_2018)
  
df2_2018 <- bind_cols(df2a_2018,
                      df2b_2018)
names(df2_2018) <- c()

column_names <- c("Group",
                  "Rate",
                  "N_2017")

colnames(df2_2018) <- column_names

df2_2018 <- df2_2018 %>%
  dplyr::select(-N_2017)

df2_2018 <- df2_2018 %>%
  dplyr::mutate(Year = 2018)

df2_2018 <- df2_2018 %>%
  mutate(Gender = case_when(str_detect(Group, "Women") ~ TRUE,
                            str_detect(Group, "Men") ~ FALSE,
                            TRUE ~ NA))

labels <- unlist(df2_2018[c(seq(1,15, by=3),16,17),1], use.names = FALSE)

dim(df2_2018)[1]

labels_3 <- c(rep(labels[1:5], each = dim(df2_2018)[1]/(length(labels)-2)),
              "HMONG",
              "CAMBODIAN")

df2_2018$Subgroup <- labels_3

df2_2018 <- df2_2018 %>% 
  mutate(Type = "Subgroup Total")

glimpse(df2_2018)

df2_2018 <- df2_2018 %>%
  mutate(Gender = case_when(Gender == TRUE ~ "Female",
                            Gender == FALSE ~ "Male",
                            TRUE ~ "All"))

df2_2018 <- df2_2018 %>% 
  mutate_if(is.character, tolower) %>%
  mutate_if(is.character, toupper)

df2_2018 <- df2_2018 %>%
  dplyr::select(-Group)
```

The dataframe we produced does not contain totals. 

```{r}
df2_2018 %>%
  print(., n = dim(.)[1])
```

We can find these totals in the PDF directly and create rows as needed

We load the PDF.

```{r}
excerpt <- image_read(here("img", "asian_youth_excerpt.png"))

excerpt
```

We add the rows.

```{r}
df2_2018 <- df2_2018 %>%
  add_row(Rate = 6.2,
          Year = 2018,
          Gender = "ALL",
          Subgroup = "ALL", 
          Type = "ASIAN TOTAL") %>%
  add_row(Rate = 6.1,
          Year = 2018,
          Gender = "FEMALE",
          Subgroup = "ALL", 
          Type = "GENDER TOTAL") %>%
  add_row(Rate = 6.4,
          Year = 2018,
          Gender = "MALE",
          Subgroup = "ALL", 
          Type = "GENDER TOTAL")
```

```{r}
df2 <- bind_rows(df2,
                 df2_2018)
```

We repeat this process again for Latino/a subgroups. 

The table, without the special formatting, looks like this.

```{r}
image3 <- image_read(here("img", "latino_a_subgroups.png"))
```

There are no whitespaces in this table.

We proceed using what we've learned while wrangling the first two tables.

```{r}
df3 <- magick::image_ocr(image3)

df3 %>%
  base::strsplit("\n") %>%
  base::unlist() %>%
  tibble::as_tibble()
```

We are often presented with scenarios where stand-alone approaches are difficult or time-consuming.

It is always best to document the steps take to respond to these scenarios. Wrangling this third table is a prime example of this. 

We are missing a row. Let's manually add the row.

```{r}
df3 <- df3 %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()

df3 <- df3 %>%
  rbind("PR, DR, Cuban 15.1 211,200")
```

We can now proceed as we did with the previous tables. 

```{r}
df3 <- df3 %>%
  dplyr::select(value) %>%
  pull(value) %>%
  str_split(" ")

df3b <- map(df3, tail, 2) %>%
  map(~gsub("[,]+|[.]+", "",.)) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  mutate_if(is.character, as.numeric) %>%
  mutate_at(vars(-X2), ~ . * 0.1) %>%
  tibble() 

df3a <- df3 %>%
  map(~paste(.,collapse = "")) %>%
  map(~gsub("[[:digit:]]+|[[:punct:]]+", "",.)) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  tibble()

rm(df3)
  
df3 <- bind_cols(df3a, df3b)
names(df3) <- c()

column_names <- c("Group",
                  "Rate",
                  "N_2017")

colnames(df3) <- column_names

```

If we look at the last few rows, we see that there is a typo. There are two female groups.

```{r}
tail(df3)
```

Sometimes when wrangling text data, we will come across a typo. We need to determine how to respond to the typo and make note of it. It's often best to consult a secondary source to confirm that changes made are accurate. 

For the purposes of this case study, we will assume that the first of the two rows represents male disconnection rates in the Latino/a subgroup; this would be consistent with the ordering of genders in the previous subgroups. 

Let's make the correction to the typo.

```{r}
df3 <- df3 %>%
  mutate(Group = case_when(Group == "PRDRCubanFemale" & N_2017 == 114500 ~ "PRDRCubanMale",
                         TRUE ~ Group))
```

It looks like we've succesfully corrected the typo.

```{r}
tail(df3)
```

We can continue with the process we've developed now that we have made the correction.

```{r}
df3 <- df3 %>%
  dplyr::select(-N_2017)

df3 <- df3 %>%
  dplyr::mutate(Year = 2017)

df3 <- df3 %>%
  mutate(Gender = case_when(str_detect(Group, "Female") ~ TRUE,
                            str_detect(Group, "Male") ~ FALSE,
                            TRUE ~ NA),
         Subgroup = str_remove_all(Group,
                                   pattern = paste(c("Female",
                                                     "Male",
                                                     "LATINO",
                                                     "Latino",
                                                     "Latina"),
                                               collapse = "|"))) %>%
  mutate(Subgroup = na_if(Subgroup, ""))

glimpse(df3)

df3 <- df3 %>% 
  mutate(Type = case_when(is.na(Gender) & is.na(Subgroup) ~ "Latino/a Total",
                          is.na(Gender) & !is.na(Subgroup) ~ "Subgroup Total",
                          !is.na(Gender) & is.na(Subgroup) ~ "Gender Total",
                          TRUE ~ "Subgroup Total"))

glimpse(df3)

df3 <- df3 %>%
  mutate(Gender = case_when(str_detect(Group, "Female") ~ "Female",
                            str_detect(Group, "Male") ~ "Male"))

df3 <- df3 %>% 
  mutate_if(is.character, tolower) %>%
  mutate_if(is.character, toupper)

df3 <- df3 %>%
  mutate(Gender = replace_na(Gender, "ALL"),
         Subgroup = replace_na(Subgroup, "ALL")) %>%
  dplyr::select(-Group) %>%
  mutate(Subgroup)

df3 <- df3 %>%
  mutate(Subgroup = case_when(Subgroup == "SOUTHAMERICAN" ~ "SOUTH AMERICAN",
                              Subgroup == "CENTRALAMERICAN" ~ "CENTRAL AMERICAN",
                              Subgroup == "PRDRCUBAN" ~ "PR/DR/CUBAN",
                              TRUE ~ Subgroup))
```

Let's add the 2018 data to this dataframe.

We import the image. 

```{r}
image5 <- image_read(here("img", "latino_a_subgroups_2018.png"))

df3_2018 <- magick::image_ocr(image5)
```

As you can see, we have repeated newlines (`\n`). We can remove these with some simplex regex.

```{r}
df3_2018 <- gsub('([\n])\\1+',
                 '\\2',
                 df3_2018)

df3_2018 <- gsub("[[:punct:]]+",
                 "",
                 df3_2018)
```

We proceed, making slight modifications to the process as needed.

```{r}
df3_2018 <- df3_2018 %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()

df3_2018 <- df3_2018 %>%
  dplyr::select(value) %>%
  pull(value) %>%
  str_split(" ")

df3_2018 <- lapply(df3_2018,
                   function(x) x[nchar(x) >= 1])

df3a_2018 <- df3_2018 %>%
  map(~paste(.,collapse = "")) %>%
  map(~gsub("[[:digit:]]+|[[:punct:]]+", "",.)) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  tibble()

df3b_2018 <- map(df3_2018, tail, 2) %>%
  do.call(rbind,.) %>%
  data.frame() %>%
  mutate_if(is.character, as.numeric) %>%
  mutate_at(vars(-X2), ~ . * 0.1) %>%
  tibble() 

rm(df3_2018)
  
df3_2018 <- bind_cols(df3a_2018,
                      df3b_2018)
names(df3_2018) <- c()

column_names <- c("Group",
                  "Rate",
                  "N_2017")

colnames(df3_2018) <- column_names

df3_2018 <- df3_2018 %>%
  dplyr::select(-N_2017)

df3_2018 <- df3_2018 %>%
  dplyr::mutate(Year = 2018)

df3_2018 <- df3_2018 %>%
  mutate(Gender = case_when(str_detect(Group, "Women") ~ TRUE,
                            str_detect(Group, "Men") ~ FALSE,
                            TRUE ~ NA))

labels <- unlist(df3_2018[seq(1,12, by =3),1], use.names = FALSE)

dim(df3_2018)[1]

labels_3 <- rep(labels, each = dim(df3_2018)[1]/length(labels))

df3_2018$Subgroup <- labels_3

df3_2018 <- df3_2018 %>% 
  mutate(Type = "Subgroup Total")

glimpse(df3_2018)

df3_2018 <- df3_2018 %>%
  mutate(Gender = case_when(Gender == TRUE ~ "Female",
                            Gender == FALSE ~ "Male",
                            TRUE ~ "All"))

df3_2018 <- df3_2018 %>% 
  mutate_if(is.character, tolower) %>%
  mutate_if(is.character, toupper)

df3_2018 <- df3_2018 %>%
  dplyr::select(-Group)

df3_2018 <- df3_2018 %>%
  mutate(Subgroup = case_when(Subgroup == "SOUTHAMERICAN" ~ "SOUTH AMERICAN",
                              Subgroup == "CENTRALAMERICAN" ~ "CENTRAL AMERICAN",
                              Subgroup == "PRDRCUBAN" ~ "PR/DR/CUBAN",
                              TRUE ~ Subgroup))
```

We load the PDF.

```{r}
rm(excerpt)
excerpt <- image_read(here("img", "latino_a_youth_excerpt.png"))

excerpt
```

We add the rows.

```{r}
df3_2018 <- df3_2018 %>%
  add_row(Rate = 12.8,
          Year = 2018,
          Gender = "ALL",
          Subgroup = "ALL", 
          Type = "LATINO/A TOTAL") %>%
  add_row(Rate = 13.3,
          Year = 2018,
          Gender = "FEMALE",
          Subgroup = "ALL", 
          Type = "GENDER TOTAL") %>%
  add_row(Rate = 12.3,
          Year = 2018,
          Gender = "MALE",
          Subgroup = "ALL", 
          Type = "GENDER TOTAL")
```

We add the 2018 data to the dataframe

```{r}
df3 <- bind_rows(df3,
                 df3_2018)
```

### Map

We will use multiple images to import the data on page 36 to produce maps. 

<style>
div.red { background-color:#ffcccb; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**MICHAEL ONTIVEROS**

*This code is not complete. If there is time, we will return to it! Magick is having trouble with quadrant 1 and 4. I could not figure out why.*
</div>

```{r, eval=FALSE}
quadrant1 <- image_read(here("img", "state_quadrant1.png"))
quadrant2 <- image_read(here("img", "state_quadrant2.png"))
quadrant3 <- image_read(here("img", "state_quadrant3.png"))
quadrant4 <- image_read(here("img", "state_quadrant4.png"))

quadrant1 <- magick::image_ocr(quadrant1)
quadrant2 <- magick::image_ocr(quadrant2)
quadrant3 <- magick::image_ocr(quadrant3)
quadrant4 <- magick::image_ocr(quadrant4)

labels_quad1_3 <- paste0(quadrant1, quadrant3)
labels_quad2_4 <- paste0(quadrant2, quadrant4)

labels_quad1_3 <- labels_quad1_3 %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()

labels_quad2_4 <- labels_quad2_4 %>%
  strsplit("\n") %>%
  unlist() %>%
  as_tibble()

df1 <- df1 %>%
  dplyr::select(value) %>%
  pull(value) %>%
  str_split(" ")
```

```{r, eval= FALSE}
data_map <- map_data("state") %>%
  filter(region=="california")

years <- c(seq(2008,2016,by=2),2017)

index_rep <- dim(data_map)[1]

data_map <- bind_rows(replicate(length(years), data_map, simplify = FALSE))

data_map$year <- rep(years, each = index_rep)

data_map <- data_map %>%
  group_by(region, year) %>%
  mutate(rank_ran = rank(year, ties.method = "random"))

data_map <- data_map[order(data_map$order),]

library(gganimate)

ggplot(data_map, aes(x = long, y = lat, group = group, fill=rank_ran)) +
  geom_polygon() +
  transition_time(time = year)

```

## **Data Analysis**
*** 

**Repeated Cross-sectional Data**

We have pooled (repeated) [cross-sectional](https://en.wikipedia.org/wiki/Cross-sectional_data?oldformat=true) data.

This is data produced from repeated measurement of a [population](https://en.wikipedia.org/wiki/Population?oldformat=true) over time.

It is often infeasible to collect data for an entire population at once. However, we can still obtain meaningful measures using a random [sample](https://en.wikipedia.org/wiki/Sampling_(statistics)?oldformat=true) of the population. 

At specific time-points, data is collected from a sample of the population. The individuals in each sample are not necessarily the same individuals. This separates pooled cross-sectional data from panel data, which is longitudinal data from repeated measurement of the same people.   

By sampling from a population at multiple time points, we can generate population level statistics. Although these statistics have some random error, they can provide insight into how the measure variable is changing in a population over time.

We can accomplish this by plotting the measured values over time. Sometimes, however, the trend isn't exactly clear. Fortunately, there are statistical methods to resolve this issue.

The Mann-Kendall trend test—a variation of the [Kendall rank correlation coefficient](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient?oldformat=true)—tests whether there is a monotonic association, an association that does not increase or decrease but remains static across a dimension.

Recall the youth disconnection rates for Native Americans, some of the highest in the first table we examined. 

```{r}
image_example
```

Let's conduct a Mann-Kendall test for trend.

We can accomplish this with the `Kendall::MannKendall()` function. The `Kendall::MannKendall()` accepts a vector of data for which a trend may be observed. [Consulting the documentation for the `Kendall::MannKendall()` function available on CRAN](https://rdrr.io/cran/Kendall/man/MannKendall.html), we can "test for a a monotonic trend in a time series".

```{r}
df1 %>%
  filter(Gender == "ALL",
         Race == "NATIVE AMERICAN") %>%
  pull(Rate) %>%
  MannKendall(.) %>%
  summary()
```

There does not appear to be a change in the trend. However, it's important to note that we only have `r length(df1 %>% filter(Gender == "ALL", Race == "NATIVE AMERICAN") %>% pull(Rate))` observations.

We can also explore the trend using [simple linear regression](https://en.wikipedia.org/wiki/Simple_linear_regression?oldformat=true). 

```{r}
df1 %>%
  filter(Gender == "ALL",
         Race == "NATIVE AMERICAN") %>%
  lm(Rate ~ Year, data = .) %>%
  summary()
```

For each one year change, the mean increase in disconnection rates is `r (df1 %>% filter(Gender == "ALL", Race == "NATIVE AMERICAN") %>% lm(Rate ~ Year, data = .))[["coefficients"]]["Year"]`. This relationship is not statistically significant. Again, we are largely limited by the number of observations in this dataset. 

We can visualize the relationship above.

```{r}
df1 %>%
  filter(Gender == "ALL",
         Race == "NATIVE AMERICAN") %>%
  ggplot(aes(x = Year, y = Rate)) +
  geom_smooth(method = "lm", color = "red") + 
  geom_point() + 
  scale_x_continuous(breaks = seq(2008, 2018, by = 1),
                     labels = seq(2008, 2018, by = 1),
                     limits = c(2008, 2018)) +
  theme_minimal() +
  labs(title = "Youth Disconnection Rates of Native American Youth",
       subtitle = "2008 - 2017",
       x = "Year",
       y = "Disconnection Rate")
```

As we can see, there is a large amount of uncertainty around the fitted line. 

Let's visualize the data! 

## **Data Visualization**
*** 

Let's reproduce the example below.

```{r, out.width = "100%", echo = FALSE, fig.align ="center"}
include_graphics(here::here("img", "Making_the_Connection_plot.png"))
```

We can create a version of the above example with `ggplot` from `tidyverse`.

There are color identifying websites only such as [this](https://imagecolorpicker.com/en/).

Using one of these websites, we identify the [hex triplet](https://en.wikipedia.org/wiki/Web_colors?oldformat=true) for the color used in the visualization included in the PDF: `#008393`. 

```{r}
fa_figurine <- image_read("https://upload.wikimedia.org/wikipedia/commons/7/7c/User_font_awesome.svg")

fa_figurine <- image_fill(fa_figurine,
                          color = "#008393", 
                          point = "+800+800",
                          fuzz = 0)

fa_figurine <- image_fill(fa_figurine,
                          color = "#008393", 
                          point = "+800+1000",
                          fuzz = 0)

df1 %>%
  filter(Type == "RACE TOTAL") %>%
  ggplot(aes(x = Year, y = Rate, group=Race)) +
  geom_line(color = "#008393", size = 0.5) +
  geom_point(color = "#008393", size = 3) +
  scale_x_continuous(breaks = seq(2008,2018, by=1),
                     limits = c(2008,2018)) +
  scale_y_continuous(breaks = seq(5,30, by =5),
                     limits = c(5,30)) +
  draw_image(fa_figurine, x = 2017, y = 23.5, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 17.5, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 13, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 9, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 6.5, scale = 2) +
  labs(title = "FIGURE 1 YOUTH DISCONNECTION BY RACE AND ETHNICITY, 2008 - 2017",
       y = "YOUTH DISCONNECTION (%)") +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank())
```

We can build off of this idea, using a custom color palette to create a gradient based off the color used. 

```{r}
custom_pal <- colorRampPalette(c("white", "#008393"))
gender_n <- 3

asian_total <- df2 %>%
  filter(Year == 2017) %>%
  filter(Gender == "ALL",
         Subgroup == "ALL") %>%
  pull(Rate)

df2 %>%
  filter(Year == 2017) %>%
  complete(Gender, Subgroup) %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Rate, ties.method = "min")) %>%
  group_by(Subgroup) %>%
  mutate(rank_all = sub_rank[Gender == "ALL"]) %>%
  ungroup() %>%
  mutate(Subgroup = fct_reorder(Subgroup, rank_all)) %>%
  ggplot(aes(x = Subgroup, y = Rate, fill = Gender)) +
  geom_hline(yintercept = asian_total, 
             color = "black",
             linetype = 2) + 
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY ASIAN SUBGROUP, 2017",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,20,2),
                     labels = seq(0,20,2),
                     limits = c(0,20)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  annotate("text", label = 'bold("ASIAN TOTAL")',
           color = "#008393", 
           size = 3,
           x = 1.2,
           y = asian_total + 1,
           parse = TRUE)
```

From the above plot, it becomes apparent that the Hmong subgroup produces a small proportion of the total number of asian disconnected youth. The Asian total youth disconnection rate is more alike the youth disconnection rates for all other subgroups than the Hmong youth disconnection rate.

We can confirm this by revisiting the table.

```{r}
image2
```

The Hmong group represents `r round((8300*100)/145600)`% of all Asian disconnected youth. 

This shows the importance of adding small details such as the composite line to plots. It helps provide a simple yet nuanced picture of what is going on. 

Lastly, we can add annotations to add provide even more depth to the visualization. 

```{r}
latino_a_total <- df3 %>%
  filter(Year == 2017) %>%
  filter(Gender == "ALL",
         Subgroup == "ALL") %>%
  pull(Rate)

df3 %>%
  filter(Year == 2017) %>%
  complete(Gender, Subgroup) %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Rate, ties.method = "min")) %>%
  group_by(Subgroup) %>%
  mutate(rank_all = sub_rank[Gender == "ALL"]) %>%
  ungroup() %>%
  mutate(Subgroup = fct_reorder(Subgroup, rank_all)) %>%
  ggplot(aes(x = Subgroup, y = Rate, fill = Gender)) +
  geom_hline(yintercept = latino_a_total, 
             color = "black",
             linetype = 2) + 
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY LATINO/A SUBGROUP, 2017",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,20,2),
                     labels = seq(0,20,2),
                     limits = c(0,20)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  annotate("text", label = 'bold("LATINO TOTAL")',
           color = "#008393", 
           size = 3,
           x = 1.2,
           y = latino_a_total + 1,
           parse = TRUE)
```

```{r}
df2 %>%
  complete(Gender, Subgroup, Year) %>%
  group_by(Subgroup) %>%
  mutate(missing = sum(is.na(Rate))) %>%
  filter(missing == 0) %>%
  dplyr::select(-missing) %>%
  ungroup() %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Rate, ties.method = "min")) %>%
  group_by(Subgroup, Year) %>%
  mutate(rank_all = sub_rank[Gender == "ALL"]) %>%
  ungroup() %>%
  group_by(Year) %>%
  mutate(threshold = Rate[Gender == "ALL" & Subgroup == "ALL"]) %>%
  ungroup() %>%
  mutate(Subgroup = fct_reorder(Subgroup, rank_all)) %>%
  ggplot(aes(x = Subgroup, y = Rate, fill = Gender)) +
  facet_wrap(Year ~., ncol = 1) +
  geom_hline(aes(yintercept = threshold), linetype = 2) +
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY ASIAN SUBGROUP, 2017-2018",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,10,2),
                     labels = seq(0,10,2),
                     limits = c(0,10)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
df3 %>%
  complete(Gender, Subgroup, Year) %>%
  group_by(Subgroup) %>%
  mutate(missing = sum(is.na(Rate))) %>%
  filter(missing == 0) %>%
  dplyr::select(-missing) %>%
  ungroup() %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Rate, ties.method = "min")) %>%
  group_by(Subgroup, Year) %>%
  mutate(rank_all = sub_rank[Gender == "ALL"]) %>%
  ungroup() %>%
  group_by(Year) %>%
  mutate(threshold = Rate[Gender == "ALL" & Subgroup == "ALL"]) %>%
  ungroup() %>%
  mutate(Subgroup = fct_reorder(Subgroup, rank_all)) %>%
  ggplot(aes(x = Subgroup, y = Rate, fill = Gender)) +
  facet_wrap(Year ~., ncol = 1) +
  geom_hline(aes(yintercept = threshold), linetype = 2) +
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY LATINO/A SUBGROUP, 2017",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,20,2),
                     labels = seq(0,20,2),
                     limits = c(0,20)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1))
```

## **Summary**
*** 

## **Suggested Homework**
*** 

1) Find another table in the document. Find differences between groups with the process described above. 

## **Helpful Links**
*** 


avocado*This concepts listed here must be revisited.*


<u>Terms and concepts covered:</u>  

[Tidyverse](https://www.tidyverse.org/){target="_blank"}  
[RStudio cheatsheets](https://rstudio.com/resources/cheatsheets/){target="_blank"}  
[Inference](https://www.britannica.com/science/inference-statistics){target="_blank"}  
[Regression](https://lindeloev.github.io/tests-as-linear/){target="_blank"}  
[Different types of regression](https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/){target="_blank"}  
[Ordinary least squares method](http://setosa.io/ev/ordinary-least-squares-regression/){target="_blank"}  
[Residual](https://www.statisticshowto.datasciencecentral.com/residual/){target="_blank"}  

<u>Packages used in this case study: </u>

 Package   | Use                                                                         
---------- |-------------
[**here**](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data
[**tidyverse**](https://readr.tidyverse.org/){target="_blank"}      | for data science operations
[**pdftools**](https://readr.tidyverse.org/){target="_blank"}      | to manage PDF documents
[**magick**](https://cran.r-project.org/web/packages/magick/vignettes/intro.html#Kernel_convolution){target="_blank"}      | for image processing 

## Acknowledgements

We would like to acknowledge [Tamar Mendelson](https://www.jhsph.edu/faculty/directory/profile/1770/tamar-mendelson) for assisting in framing the major direction of the case study.

We would also like to acknowledge the [Bloomberg American Health Initiative](https://americanhealth.jhu.edu/) for funding this work. 