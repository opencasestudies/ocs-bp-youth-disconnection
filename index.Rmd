---
title: "Open Case Studies : Disparities in Youth Disconnection"
css: style.css
output:
  html_document:
    self_contained: yes
    code_download: yes
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes

---

<style>
#TOC {
  background: url("https://opencasestudies.github.io/img/logo.jpg");
  background-size: contain;
  padding-top: 240px !important;
  background-repeat: no-repeat;
}
</style>







<style>
div.red { background-color:#ffcccb; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**MICHAEL ONTIVEROS**

*There are some existing typos in the tables in addition to those produced during the use of Magick. I made some assumptions along the way, documenting them. These need to be checked for accuracy.*
</div>

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE, cache = FALSE,
                      fig.align = "center", out.width = '90%')
library(here)
library(knitr)
```


#### {.outline }
```{r, echo = FALSE, out.width = "800 px", eval=FALSE}
knitr::include_graphics(here::here("img", "mainplot.png"))
```

####

## {.disclaimer_block}

**Disclaimer**: The purpose of the [Open Case Studies](https://opencasestudies.github.io){target="_blank"} project is **to demonstrate the use of various data science methods, tools, and software in the context of messy, real-world data**. A given case study does not cover all aspects of the research process, is not claiming to be the most appropriate way to analyze a given data set, and should not be used in the context of making policy decisions without external consultation from scientific experts. 


## {.license_block}

This work is licensed under the Creative Commons Attribution-NonCommercial 3.0 [(CC BY-NC 3.0)](https://creativecommons.org/licenses/by-nc/3.0/us/){target="_blank"}  United States License.


## {.reference_block}

To cite this case study please use:

Wright, Carrie, and Ontiveros, Michael and Jager, Leah and Taub, Margaret and Hicks, Stephanie. (2020). https://github.com/opencasestudies/ocs-youth-disconnection-case-study. Disparities in Youth Disconnection (Version v1.0.0).

## **Motivation**
*** 

According to this [report](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf) youth disconnection although generally showing decreasing trends for the past 7 years, shows **racial and ethnic disparities**, where some groups are showing increased rates of disconnection.

So what does the term **"youth disconnection"** mean?

According to [Measure of America](https://www.ssrc.org/programs/view/moa/){target="_blank"} (a nonpartisan project of the nonprofit [Social Science Research Council](https://www.ssrc.org/){target="_blank"} that is focused on opportunity in the United States) disconnected youth are:

> "young people between the ages of **16 and 24** who are **neither working nor in school**"

They state that such disconnection hinders these individuals to aquire skills and create relationships necessary to have a sucessful adulthood. 

They state that:

> "people who experience a period of disconnection as young adults go on to **earn less** and are **less likely** to be **employed, own a home, or report good health** by the time they reach their thirties"

Disconnected youth are also referred to as **opportunity youth**, which has the added positive connotation that promoting such individuals can be beneficial not only for these individuals but also for their communties and for society. 

We will expand beyond the [Measure of America annual report](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf){target="_blank"} to take a deeper look at differences of specific groups of youths. Identifying youths particularly at risk or disconnected, can help inform the design of targeted prevention and rengagement strategies.

This case study is motivated by this [article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6243446/){target="_blank"}: 

#### {.reference_block}

Mendelson, T., Mmari, K., Blum, R. W., Catalano, R. F. & Brindis, C. D. Opportunity Youth: Insights and Opportunities for a Public Health Approach to Reengage Disconnected Teenagers and Young Adults. *Public Health Rep* 133, 54S-64S (2018).

####
 
This [article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6243446/){target="_blank"} describes strategies for prevention of disconnection and reengagement of discconnected youth and how such interventions could greatly positively impact opportunity youth for the entire trajectory of their lives and for future generations. It also points out that indeed their are disparities among different racial/ethnic groups.


## **Main Questions**
*** 

#### {.main_question_block}
<b><u> Our main questions: </u></b>

1) How have youth disconnection rates in American youth changed since 2008?   
2) In particular, how has this changed for different gender and ethnic groups? Are any groups particularly disconnected? 

####

## **Learning Objectives** 
*** 

In this case study, we will demonstrate how to import and wrangle data available in the <u>**P**</u>ortable <u>**D**</u>ocument <u>**F**</u>ormat (**PDF**). We will especially focus on using packages and functions from the [`Tidyverse`](https://www.tidyverse.org/){target="_blank"}, such as `dplyr`, `ggplot2`. The tidyverse is a library of packages created by RStudio. While some students may be familiar with previous R programming packages, these packages make data science in R more legible and intuitive.

The skills, methods, and concepts that students will be familiar with by the end of this case study are:

Data science skills:  

1. Importing data from PDF files using the `magick` package  
2. Apply action verbs in `dplyr` for data wrangling  
3. How to pivot between "long" and "wide" datasets (`tidyr`)  
4. Joining together multiple datasets using `dplyr`  
5. How to create data visualizations with `ggplot2` that are in a similar style to an existing image  

Statistical concepts and methods:  

1. Implementation of the Mann-Kendall trend test  
2. Interpretation of the Mann-Kendall trend test  


```{r, out.width = "20%", echo = FALSE, fig.align ="center"}
include_graphics("https://tidyverse.tidyverse.org/logo.png")
```

*** 

We will begin by loading the packages that we will need:

```{r}
library(here)
library(tidyverse)
library(dplyr)
library(tidyr)
library(magrittr)
library(pdftools)
library(magick)
library(cowplot)
library(Kendall)
```



 Package   | Use                                                                         
---------- |-------------
[**here**](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data
[**tidyverse**](https://readr.tidyverse.org/){target="_blank"}      | for data science operations
[**pdftools**](https://readr.tidyverse.org/){target="_blank"}      | to manage PDF documents
[**magick**](https://cran.r-project.org/web/packages/magick/vignettes/intro.html#Kernel_convolution){target="_blank"}      | for image processing 

The first time we use a function, we will use the `::` to indicate which package we are using. Unless we have overlapping function names, this is not necessary, but we will include it here to be informative about where the functions we will use come from.

## **Context**
*** 

So how does youth disconnection happen and what impact does it have?


There are many known **risk factors**, which have been identified in a variety of contexts (from family, friends, school, community, society) including:  

 - poverty (disconnected youth are nearly twice as likely to live in poverty and receive Medicaid)  
 - racial/ethnic disparities (findings suggest that these persist even when controlling for income)  
 - residential environment (in 2016 while 11.7% was the national average, 24% of people age 16-24 in the rural South were disconnected)  
 - poor academic performance  
 - poor mental health  
 - substance use disorders  
 - parental unemployment  
 - trauma exposure  
 - association with socially deviant peers 
 - school policies such as "one strike and you're out" - which is a zero tolerance school expulsion policy and shown to increase dropouts and incarceration rates
 
 These risk factors make it more likely for young people to miss out on education, training, and networking that can act as a foundation for a sucessful career.
 
There are also many known **negative consequences** associated with youth disconnection including but not limited to:

- chronic unemployment
- poverty
- poor menthal health and poor general health (in a 2002 study - youths discoonected for 6 or more months were 3 times more likely to develop depression or other mental health disorder)
- crimial behavior (in a 2002 study - youths discoonected for 6 or more months were 5 times more likely to have a criminal record)
- incarceration
- early mortality 


```{r, out.width= "400px",echo=FALSE}
knitr::include_graphics(here::here("img", "jon-tyson-ajzN2AYNi1U-unsplash.jpg"))
```
<span>Photo by <a href="https://unsplash.com/@jontyson?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jon Tyson</a> on <a href="https://unsplash.com/s/photos/unemployment?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>

Furthermore, in 2012 it was estimated that each disconnected youth costs taxpayers $250000 during a life time due to lost tax revenue and costs for social sercices, heath care and criminal justice.

Youth disconnection can be described as a continuum, as some youths will be disconnected for a brief time, while others are chronically disconnected. Additionally, while an individual who is out of school and work and also has poor support from the realtionships of others may be further disconnected than an individual who has social support.

Here is an illustration of risk factors, protective factors and the continuum of disconnection:

```{r, echo = FALSE, out.width = "800 px"}
knitr::include_graphics(here::here("img", "risk_factors.png"))
```
##### [[source]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6243446/pdf/10.1177_0033354918799344.pdf){target="_blank"} 


### Strategies to mitigate youth disconnection

Many programs have identified useful strategies in rengaging disconnected youth or preventing discconection of youth. 

generally speaking, most programs focus on reengagement strategies, however, prevention strategies are likely to be just as important. 

Reserach suggests that active involvement with at risk youth from infancy and across multiple developmental stages through young adulthood whould be the most beneficial.

In fact, the quality of parental caregiving of infants age 6-24 months has actually been shown to be a predictor of high school dropout rates! Thus early interventions may be very important and consistent continual engagement may prevent further disconnection of youths.

Prevention strategies include:  

- Preschool  
- [The Good Behavior Game](https://www.goodbehaviorgame.org/good-behavior-game-what-is-it){target="_blank"}  
- Strengthening family and community connections  
- Promoting academic and career engagement  
- Life skills training for youths and families  
- Education about substance abuse  
- [Cognitive behavioral therapy](https://www.apa.org/ptsd-guideline/patients-and-families/cognitive-behavioral){target="_blank"}    


See [here](https://youth.gov/evidence-innovation/program-directory?keywords=&field_pd_factors_risks_tid=413&field_pd_factors_protective_tid=All){target="_blank"} and [here](https://goc.maryland.gov/wp-content/uploads/sites/8/2015/10/Program-Models-for-Serving-Opportunity-Youth.pdf){target="_blank"} for listings of programs dedicated to rengaging disconnected youth or preventing disconnection.

See [here](https://www.communitiesthatcare.net/){target="_blank"} and 
[here](https://extension.psu.edu/promoting-school-community-university-partnerships-to-enhance-resilience){target="_blank"} for particular examples.


The statistics used in this section came from this [article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6243446/){target="_blank"}.

## **Limitations**
*** 

There are some important considerations regarding this data analysis to keep in mind: 

1) This data used in the [Measure of America](https://www.ssrc.org/programs/view/moa/){target="_blank"}  project reports from the is derived from [American Community Survey(ASC)](https://www.census.gov/programs-surveys/acs){target="_blank"} which excludes or underrepresents certain opportunity youth groups, such as youths in the juvenile justice system, youths in the foster care system, and homeless youths as the survey is conducted on households. Furthermore, youths who may be more disconnected for other reasons besides not being in work or school, such as dealing with the added challenge of being a teenage mother, or being abused is not available in this dataset. Thus, this data likely underestimates youth disconnection rates. 

2) Data about certain group [intersections](https://www.vox.com/the-highlight/2019/5/20/18542843/intersectionality-conservatism-law-race-gender-discrimination){target="_blank"} (meaning for example individuals of a particular gender and ethnicity) or particular groups in general such as specific ethnicities or gender or sexual identity groups such as LGBT (lesbian/gay/bisexual/transgender/queer and questioning) or nonbinary gender populations is unfortunately not available in the data used in this analysis and in most research about this topic. Luckily however, recent years of the [ACS survey](https://www.census.gov/programs-surveys/acs){target="_blank"} has more detailed infromation about a greater number of racial and ethnic groups and racial/ethnic intersections.

3) The statistical procedures we are using may be overly simplistic. *In all data analysis, we need to be wary about deriving meaning from the statistical procedures we use*.

4) Using image processing tools can be very helpful. The manner in which data is obtained with image processing tools is what we would describe as a **black box process**, <u>*a process with known inputs and outputs but unknown mechanics*</u>. Because we are unaware of how our outputs are generated from our inputs, we need to be wary of the output. With the small output we are creating in this case study, a visual inspection should suffice. 


## **What are the data?**
*** 

In this case study we will be using data related to youth disconnection from the two following reports from the [Measure of America](https://www.ssrc.org/programs/view/moa/){target="_blank"}  project:

> Measure of America is a nonpartisan project of the nonprofit [Social Science Research Council](https://www.ssrc.org/){target="_blank"}  founded in 2007 to create easy-to-use yet methodologically sound tools for understanding well-being and opportunity in America. Through reports, interactive apps, and custom-built dashboards, Measure of America works with partners to breathe life into numbers, using data to identify areas of highest need, pinpoint levers for change, and track progress over time.

1. Lewis, Kristen. [Making the Connection: Transportation and Youth Disconnection](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf){target="_blank"} . New York: Measure of America, Social Science Research Council, 2019.  (Data up to 2017)

```{r, out.width="400px", echo = FALSE}
knitr::include_graphics(here::here("img", "Making_the_Connection.png"))
```

2. : Lewis, Kristen. [A Decade Undone: Youth Disconnection in the Age of Coronavirus](https://ssrc-static.s3.amazonaws.com/moa/ADecadeUndone.pdf){target="_blank"}. New York: Measure of America, Social Science Research Council, 2020. (Data up to 2018)

```{r, out.width="400px", echo = FALSE}
knitr::include_graphics(here::here("img", "A_Decade_Undone.png"))
```

The data used in these reports comes from the [American Community Survey(ASC)](https://www.census.gov/programs-surveys/acs){target="_blank"}, which is the largest survey conducted by the United States Census Bureau. The survey started in 2005 and collects data for 3.5 million households annually. Data is collected about ancestry, citizehsip, income, employment, disability among many other aspects. See [here](https://en.wikipedia.org/wiki/American_Community_Survey){target="_blank"} for more detailed information about the survey.

According to Wikipedia (https://en.wikipedia.org/wiki/American_Community_Survey){target="_blank"}:

> Data is collected by internet, mail, telephone interviews and in-person interviews...About 95 percent of households across all response modes ultimately respond... ACS responses are confidential... and "immune from legal process"

> It is a mandatory survey, it is governed by federal laws that could impose a fine of as much as $5,000 for refusing to participate.


We are particuarlly interesed in the following tables on the last page of the [Measure of America 2019 report](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf){target="_blank"}:

```{r, echo = FALSE, gender_race_eth_2019}
knitr::include_graphics(here::here("img", "gender_race_ethnicity_overview.png"))
```

We are particuarlly interesed in the tables on the following pages from the [Measure of America 2020 report](https://ssrc-static.s3.amazonaws.com/moa/ADecadeUndone.pdf){target="_blank"}:


```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "latino_2018_overview.png"))
```

```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "asian_2018_overview.png"))
```



## **Data Import**
*** 

One way to import data from a pdf is to use the `pdf_text()` function of the `pdftools` package. The `here()` function of the `here` package can allow us to specify where the document that we want to import is located easily, starting from the directory where a `.Rproj` file is located. In this case, we will import the `Making_the_Connection.pdf` in the `docs` directory. *Note this is the case if you pull the repository from github.*

```{r}
pdf_tools_example <- pdftools::pdf_text(here::here("docs","Making_the_Connection.pdf"))
```

We can take a look at the output for the page with our table of interests by simpy using brackets `[]` around the page number. The page we are interested in (athough called 39 in the report) is the 44th page, which looks like this:

```{r, gender_race_eth_2019, echo=FALSE}
```

#### {.scrollable }
```{r}
# Scroll through the output!
pdf_tools_example[44]
```
####

From the output, it's clear that a relatively large amount of manipulation will be required to wrangle this data. If you are interested in learning more about this method, please see this [case study](https://opencasestudies.github.io/ocs-bp-rural-and-urban-obesity/){target="_blank"} and this [case study](https://opencasestudies.github.io/ocs-bp-rural-and-urban-obesity/){target="_blank"}.

While not impossible, using the `pdftools` package in this scenario will be a bit challenging becuase of how the multiple tables are displayed on this page.

While our output may be reproducible, this process may be too time consuming.

Fortunately, there is another way we can proceed to wrangle the data. 

We will demonstrate how to produce reproducible tables with image processing software in `R` using  a package called `magick` which allows for the extraction of text from images. The advantage of this option, is that we can take a screenshot of just a piece of the page to wrangle. 

For demonstrative purposes, we will import two sets of data. The first set of data will be used to highlight common errors that the image processing software may produce. The second set of data will be used to demonstrate how to circumvent these errors and produce reproducible datasets efficiently.


### Importing with `magick`

We will now import the data using the `magick` package which allows for the improtation of images. 

First we will take a screenshot of the top part of the gender, race, and ethnicity table on the last page of the [2019 Measure of America Report](https://ssrc-static.s3.amazonaws.com/moa/Making%20the%20Connection.pdf){target="_blank"}.

We can show what this file looks like in this rendered rmarkdown website by using the `include_graphics()` function of the `knitr` package.

```{r}
knitr::include_graphics(here::here("img", "gender_race_ethnicity.png"))
```

Now, we will use the `image_read()` function of the `magick` package to import this image.

We can then use teh `image_info()` function to make sure that the import worked and to get information about the size, format and color of the image.

```{r, dpi = 1000}
image_example <- magick::image_read(here::here("img", "gender_race_ethnicity.png"))

magick::image_info(image_example)
```
Now let's take a look at our image in R! Now that we have imported it to see this image, we simply need to type the name of the image.

```{r}
image_example
```

Nice!

We will demonstrate in a bit that the top part of the table causes issues when extracting the text from this image.  So now we will take a screen shot without the top part of the table and do the same process.

```{r, dpi = 1000}
cropped_table_gen_race_eth_2018 <- image_read(here("img", "gender_race_ethnicity2.png"))
cropped_table_gen_race_eth_2018
```
Let's import one more image just for fun. Here we will import an image directly from a URL.

```{r, out.width="20%"}
ggplot2_logo <- image_read("https://d33wubrfki0l68.cloudfront.net/2c6239d311be6d037c251c71c3902792f8c4ddd2/12f67/css/images/hex/ggplot2.png")
ggplot2_logo
```

Now we will use the `image_ocr()` function of the `magick` package to extract the text from the OCS logo image. This function uses the `tesseract` package which has tools for [optical character recognition (OCR)](https://en.wikipedia.org/wiki/Optical_character_recognition){target="_blank"}, hence the `ocr` in the function name. This allows the function to identify text in images. These OCR tools have often been developed using [machine learning](https://en.wikipedia.org/wiki/Machine_learning){target="_blank"} in which an algorithm was trained on images with and without text to "learn" to recognize text. See [here](https://towardsdatascience.com/a-gentle-introduction-to-ocr-ee1469a201aa){target="_blank"} to learn more about how OCR works.

```{r}
magick::image_ocr(ggplot2_logo)
```

Awesome! We were able to extract text from this hex sticker!

One thing to keep in mind is that this doesn't always work. Unusual font, angles text, or particular colors can be difficult for the OCR to recoginize.

Here is an example that does not work with the current version of `magick`:

```{r, out.width="20%"}
tidyverse_logo <- image_read("https://tidyverse.tidyverse.org/logo.png")
tidyverse_logo
magick::image_ocr(tidyverse_logo)
```

This is likely do to the background on this particular hex sticker.

## **Data Exploration and Wrangling**
*** 
Now let's try extracting the text from our image files.

### Major Racial and Ethnic Group Table

The first image we imported looks like this. 

```{r}
image_example
```

Now we will extract the text! 

```{r}
df1 <- magick::image_ocr(image_example)
df1
```
This looks like it worked fairly well!

You may notice that there are lots of `\n` values in the text from our image. These are [**newline**](https://en.wikipedia.org/wiki/Newline?oldformat=true) characters, which denote the end of a line of text and the start of a new line of text.  

We can use the `str_split()` function of the `stringr` package to split based on the `\n` characters in the output. We will then unlist the output using the base R `unlist()` function. By base, we mean that the function it is loaded automatically in an R session. Finally we will use the `as_tibble()` function of the `tibble` package to convert the data into [tibble](https://tibble.tidyverse.org/){target="_blank"} format, which is the tidyverse version of a data frame. This will allow us to see the values in the table much better.

To do all of these sequential steps efficiently we will use a method called piping.

***
<details> <summary>Click here if you are unfamiliar with piping in R, which uses this `%>%` operator</summary>  

By [piping](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"} we mean using the `%>%` pipe operator which is accessible after loading the `tidyverse` or several of the packages within the tidyverse like `dplyr` because they load the [`magrittr` package](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"}. 
This allows us to perform multiple sequential steps on one data input.   
</details>  
***
#### {.scrollable }
```{r}
df1 %>%
  stringr::str_split(pattern ="\n") %>%
  unlist() %>%
  tibble::as_tibble()

```
####


OK, not bad, the top looks a bit strange but the rest of the table looks fairly good, but there are some rows that look particularly strange like the row that starts with `LATINO`, or you may notice that the row for Native American females ends with `-B.4`:


```{r, echo = FALSE}

df2 <- df1 %>%
  stringr::str_split(pattern ="\n") %>%
  unlist() %>%
  tibble::as_tibble()

temp <-df2 %>%
  pull(value) %>%
  str_split(" ")
temp[13]
temp[21]
```

Data wrangling is not an exact science. The approaches we can take are extremely dependent on the data. We can exploit patterns in the data to render the output we desire. 

The first few lines of our table have quite a bit of special formatting, there are different font colors and backgrounds. As we saw previously, this can sometimes cause issues. So now we will try using the cropped version of the image.


```{r, dpi = 1000}

cropped_table_gen_race_eth_2018

df1 <- image_ocr(cropped_table_gen_race_eth_2018)

df1 <- df1 %>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()

df1



df_dis <- image_ocr(cropped_table_gen_race_eth_2018)

df_dis <- df_dis %>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()

df_dis
```

This looks much better!

Now let's spearate the first column about ethnicities with the values in the subsequent columns. We can do so using the `separate()` function of the `tidyr` pacakge based on [regular expressions](https://en.wikipedia.org/wiki/Regular_expression){target="_blank"}. Regular expressions (abbreviated regex) are notation shortcuts that describe patterns in character strings. See [here](https://github.com/rstudio/cheatsheets/raw/master/strings.pdf){target="_blank"} for an RStudio cheetsheat about them.

We want to separate by instances where a letter is followed by a space and then a number. 

We can specify any letter by using the regex `[:alpha:]` notation and any number by using the regex `[:digit]` notation. We could have listed every letter that we saw the first column ending with like so `s|e|E|O|K|N` but this would not be as reproducible (meaning maybe this would not work as well next year if a new group were added that ended in a different letter), and we might make a mistake. This is why the regex are so useful. 

```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "alpha.png"))
```
We can indicate that we want a space by using this regex:

```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "regex.png"))
```


Now to specify that we want to see a letter first followed by a space, followed by a digit, we need to use a look around: 

```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "look_around.png"))
```

We will use the "preceded by" and "followed by" look arounds. Thus `(?<=[:alpha:])` stands for any letter that appears before a space `\\s` that is followed by any digit `(?=[0-9])`. Altogether the pattern we want to separate by looks like this: `"(?<=[:alpha:])\\s(?=[0-9])"`.


Now to separate the value column into two cloumns, we can use the `separate` function of the `tidyr` pacakge to do this. This will allow us to not only split the rows by our regex expression, but also to create column names.

There are three important arguments for the `seperate()` function:  
- `col` - this specifies what column you are separating   
- `into` - this specifies the names of the new columns you are creating  
- `sep` - this specifies what character string to look for to separate by  

Thus we will separate the `value` column into `Group` and `years` columns.

```{r}
df_dis <-df_dis %>%
  tidyr::separate(col = value, into = c("Group", "Years"), sep = "(?<=[:alpha:])\\s(?=[0-9])")

df_dis
```

Looks good!

Let's also get rid of the all caps for the major categories of the `Group` column. We can convert the words to only capitalize the first letter using the `str_to_title()` function of the `stringr` package. To specifically modify the `Group` column we can use the `mutate` function of the `dplyr` package. 

We are also going to use a special pipe operator from the [`magrittr` package](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"} called the compound assignment pipe-operator or sometimes the double pipe operator. 

This allows us to use the `df_dis` as our input and reassign it at the end after all the subsequent steps have been performed, although in this case it is only one step.

```{r}
df_dis %<>%
  mutate(Group = stringr::str_to_title(Group))

df_dis
```

Nice! that looks better.

For the year data we would like to try splitting the strings for each row into different columns based on a space. Currently all the data is listed in one column called `Years`.

We can use the `separate` function of the `tidyr` pacakge again to do this. This will allow us to not only split the rows by spaces and will also allow us to remove the last two columns, as we will not provide names for these. 

#### {.scrollable }
```{r}

df_dis %<>%
tidyr::separate(col = Years, 
               into = c("2008", "2010",
                       "2012", "2014", 
                       "2016", "2017"), 
                sep = " ")

df_dis
 
```
Looks pretty good!

We appear to have an empty row at the very end. Since all the values are `NA`, we can use the `drop_na()` function  of the `tidyr` package to remove it.

```{r}
df_dis %<>%
  tidyr::drop_na()

df_dis
```

Great, now we have 18 rows.

It's important to look very carefully at the text. There are some values missing a decimal place. For example the row where the `Group` vlaue is `Asian`, the first value is missing a decimal place.

Looking at the orginal table we see that even values like 10 are represented as 10.0. 

So, to fix this we will remove all decimals (which is sort of like multiplying all values that do have a decimal by 10) and then we will multiply all values by .01 to add the decimals back. We will use the `mutate()` function combined with the `across()` function which allows us to specify which columns we want to perform a function on. We want to do this to all the year columns, so we can exclude the `Group` column by using a minus sign `-` in the `.cols` argument of the `across()` function like so: `mutate(across(.cols = -Group))`


Finally, we will use the `str_remove()` function of the `stringr` package to find instances of "." and remove them. Since "." is a regex, and indicates any character string, thus we need "\\" to have R interpret a decimal or a period instead, as we can see from the RStudio cheetsheat:

```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "regex_period.png"))

```

To pass the data from all the coulumns except our `Group` variable into our `str_remove()` function, we need to use the `.` notation as a replacement for the data that we specified by the `.cols`argument and we need to use `~` in front of the function name. 

```{r}

 df_dis %<>%
    mutate(across(.cols = -Group, ~str_remove(string = ., pattern = "\\.")))

df_dis
```


Great, now in order to multiply each value by 0.1 we need to first make the values numeric. Currently we can tell that they are character strings based on the `<char>` values listed under each column name.


<details> <summary> Click here for an explanation about data types in R and about what a character string is </summary>

There are several classes of data in R programming. 
Character is one of these classes. 
A character string is an individual data value made up of characters. 
This can be a paragraph, like the legend for the table, or it can be a single letter or number like the letter `"a"` or the number `"3"`. 
If data are of class character, than the numeric values will not be processed like a numeric value in a mathematical sense. 
If you want your numeric values to be interpreted that way, they need to be converted to a numeric class. 
The options typically used are integer (which has no decimal place) and double precision (which has a decimal place). 

</details>


To convert our values to be numeric we can use the base `as.numeric()` function. Again we will use `mutate()` and `across()`. Since this function doesn't require any arguments, we don't need to specify it's input like we just did for the `str_remove()` but we could do so as shown below.

```{r}
df_dis %<>%
   mutate(across(.cols = -Group, as.numeric))

#this is equivalent:

#df_dis %<>%
#   mutate(across(.cols = -Group, ~as.numeric(.)))

df_dis
```

Great, we can see that the year variables are now numeric as they are now type double as indicated by the `<dbl>` below each column name. See the above section about data types if you are unfamiliar with type double.

OK, now we can multiply each value by 0.1 to add our decimal points back and get back to the orginal values.

```{r}

df_dis %<>%
    mutate(across(.cols = -Group, ~ . * 0.1))

df_dis

```

Now is a good time to double check that our table looks like what we expect.


```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "gender_race_ethnicity.png"))
```

Looks good!


```{r}
df_dis %<>% 
  mutate(Race = recode(Group, "United States" = "All_races",
                                     "Female" = "All_races",
                                       "Male" = "All_races")) %>%
  mutate(Race = str_remove(Race,  pattern = " Female| Male"))

df_dis %<>% 
  mutate(Gender = str_extract(Group, "Female|Male")) %>%
  mutate(Gender = replace_na(Gender, replace = "All"))

```

Finally, we would like to change the shape of our table so that we have a new column that represents the year and a new column that represents the value for that year.

To do so we will be making our table "longer", meaning that it will have fewer columns and more rows. 
See [here](https://en.wikipedia.org/wiki/Wide_and_narrow_data){target="_blank"} for more information about different table formats, typically referred to as wide and long or sometimes narrow.

We will use the `pivot_longer()` function of the `tidyr` package to change the shape of our table. 

There are 3 main arguments in this function:   

1. `cols` - which specifies what columns to collapse  
2. `names_to` - which specifies the name of the new column that will be created that will contain the column names of the columns you are collapsing  
3. `values_to` - which specifies the name of the new column that will be created that will contain the values from the columns you are collapsing 

To specify that we want to collapse all the columns that have year values, we can chose those that contain the string `"20"` using the `contains()` function of `dplyr`. 

```{r}
dis_long <- df_dis %>%
  tidyr::pivot_longer(cols = contains("20"),
                  names_to = "Year",
                 values_to = "Rate",
              names_prefix = "Perc_") %>%
  dplyr::mutate(Year = as.numeric(Year))
```


Now we just need to do the same for the other two tables:

```{r, echo  = FALSE}

knitr::include_graphics(here::here("img", "gender_race_ethnicity_overview.png"))
```


### Asain Subgroups Table

Now let's do the same for the Asian subgroups table.

First we will start by importing a screenshot for this table without the header, as we did before. The name of the file for the screenshot is `asian_subgroups.png` and it is located in the `img` directory.

#### {.question_block}
<b><u> Question Opportunity </u></b>

Can you recall the command to import an image into R using the `magick` package?

####


<details> <summary> Click here to reveal the code. </summary>


```{r, out.width="40%"}
asian_subgroups <- image_read(here("img", "asian_subgroups.png"))
asian_subgroups
```
</details>


#### {.question_block}
<b><u> Question Opportunity </u></b>

Can you recall the command to extract the text from an image into R using the `magick` package? What about the commands to split the data into rows based on the newline regex ?

####


<details> <summary> Click here to reveal the code. </summary>


```{r}
asian_subgroups <- image_ocr(asian_subgroups)

asian_subgroups

asian_subgroups <- asian_subgroups %>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()
```

</details>

```{r}
asian_subgroups
```


As you can see, there are some strange values for some of the rows. For example the row that starts with `PAKISTANI` has a `bh` percentage of disconnected youth, and the row that should say `FILIPINO` says `UNO`.


```{r, echo = FALSE}

temp <-asian_subgroups %>%
  pull(value) %>%
  str_split(" ")
temp[16]
temp[27]
```
The rows with no values are possibly cuasing this issue.  According to the PDF, these spaces are empty to denote that the estimates are unreliable.

So we will now import and extract text from three screenshots of this table where we stop just after the row that starts with `PAKISTANI` in the first image, and then an image of the Korean rows up to the next row with no values, and finally an image starting at the row that starts with `FILIPNO`.

```{r}
Asian_sub_A <- image_read(here("img", "asian_subgroupsA.png"))
Asian_sub_B <- image_read(here("img", "asian_subgroupsB.png"))
Asian_sub_C <- image_read(here("img", "asian_subgroupsC.png"))


Asian_sub_A
Asian_sub_B
Asian_sub_C 

Asian_sub_A <- image_ocr(Asian_sub_A)
Asian_sub_B <- image_ocr(Asian_sub_B)
Asian_sub_C <- image_ocr(Asian_sub_C)

Asian_sub_A %<>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()

Asian_sub_B %<>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()

Asian_sub_C %<>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()

Asian_sub_A 
Asian_sub_B
Asian_sub_C 
```

Much better!

We can now combine the objects with the `bind_rows()` function of the `dplyr` package, which will append each of these tibbles together one after the other.

```{r}
asian <-bind_rows(Asian_sub_A, 
                  Asian_sub_B,
                  Asian_sub_C)

asian
```

Looks pretty good! 

Now we have similar wrangling steps to perform as we did previously and we will need to do the same for the Latino subgroups table . 

One option is to copy and paste code we wrote above. 
However, this is not very efficient and is error prone.
Alternatively, we can create a R function to accomplish this succinctly. 
Functions allow us to perform the same process on multiple data inputs. 
See [this other case study](https://opencasestudies.github.io/ocs-bloomberg-vaping-case-study/){target="_blank"} for more details about how to write a function.

In general, the process of writing functions involves first specifying an input that is used within the function to create an output. In this case, the data input is `table`  which will be replaced by the actual table we are working on, and then used in the subsequent steps to wrangle the data.

#### {.question_block}
<b><u> Question Opportunity </u></b>

Can you explain what each of the commands are doing within the function?

####

```{r}

clean_table <- function(table){
  table %>%
    separate(., col = value, into = c("Group", "Percentage"), sep =  "(?<=[:alpha:])\\s(?=[0-9])") %>% 
    drop_na() %>%
    mutate(Group = str_to_title(Group)) %>%
    mutate(Percentage =str_remove(string = Percentage, pattern = "\\.")) %>%
    separate(Percentage, c("Percent"), sep = " ") %>%
    mutate(Percent = as.numeric(Percent)) %>%
    mutate(Percent = Percent * 0.1) %>%
    mutate(Race = recode(Group, "United States" = "All_races",
                                     "Female" = "All_races",
                                       "Male" = "All_races")) %>%
    mutate(Race = str_remove(Race,  pattern = " Female| Male"))%>%
    mutate(Gender = str_extract(Group, "Female|Male")) %>%
    mutate(Gender = replace_na(Gender, replace = "All"))
 
}

```



```{r}
asian <- clean_table(table = asian)
asian
```

Great! this looks as we expected. 

#### {.question_block}
<b><u> Question Opportunity </u></b>

Why do we not need to use `pivot_longer()` with this data?

####


### Latino/a Subgroups Table

After trial and error, two screenshots were determined best for importing this data. The names of the files for the screenshots are `latino_a_sub_A.png` and `"latino_a_sub_B.png`. They are located in the `img` directory.

#### {.question_block}
<b><u> Question Opportunity </u></b>

Can you recall the commands to import and extract the data?

####


<details> <summary> Click here to reveal the code. </summary>

```{r}
Latino_a_imageA <- image_read(here::here("img", "latino_a_sub_A.png"))
Latino_a_imageB <- image_read(here::here("img", "latino_a_sub_B.png"))
Latino_a_imageC <- image_read(here::here("img", "latino_a_sub_C.png"))

Latino_a_A <- image_ocr(Latino_a_imageA)
Latino_a_B <- image_ocr(Latino_a_imageB)
Latino_a_C <- image_ocr(Latino_a_imageC)

```

</details>



```{r, out.width="40%"}
Latino_a_imageA
Latino_a_A

Latino_a_imageB
Latino_a_B

Latino_a_imageC
Latino_a_C
```
We can combine the strings together using the `str_c()` function (wich stands for string **collapse**) of the `stringr` package.

```{r}
latino_a <-stringr::str_c(Latino_a_A, Latino_a_B, Latino_a_C)
```

#### {.question_block}
<b><u> Question Opportunity </u></b>

Can you recall the commands to separate the data into rows and create a tibble?

####


<details> <summary> Click here to reveal the code. </summary>

```{r}
latino_a %<>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()
```
</details>

```{r}
latino_a
```
Now we can apply our function. 

```{r}
latino_a <- clean_table(table = latino_a)
latino_a
```


Let's also replace the abbreviations for Puerto Rican and Domincan.

#### {.question_block}
<b><u> Question Opportunity </u></b>

How might you do this?

####

<details> <summary> Click here to reveal the code. </summary>

We will use another `string_r` function. This function, `str_replace()` allows us to remove and replace a particular pattern. 

```{r}
latino_a %<>%
  mutate(Group = 
           str_replace(string = Group,
                     pattern = "Pr, Dr, Cuban Female",
                 replacement = "Puerto Rican, Dominican, Cuban"),
         Race = 
           str_replace(string = Race,
                     pattern = "Pr, Dr, Cuban Female",
                 replacement = "Puerto Rican, Dominican, Cuban"))

```

</details>


```{r}
tail(latino_a)
```

Great!

### 2018 Asian Subgroups Table

Now we are ready to look at the data from 2018 for the asian and latino/latina subgroups from the other [report](https://ssrc-static.s3.amazonaws.com/moa/ADecadeUndone.pdf){target="_blank"}.

Recall that this was the page with the table of interest for the asian subgroups with 2018 data:

```{r, echo = FALSE, }
knitr::include_graphics(here::here("img", "asian_2018_overview.png"))
```

As you can see, the data for the subgroups is shown in the table but the overall data for Asians is located in the text.

We will use a screen shot of each to extract the data for this year.

```{r, echo = FALSE, out.width="60%"}
knitr::include_graphics(here::here("img/asian_subgroups_2018.png"))
```
```{r, echo = FALSE, out.width="60%"}
knitr::include_graphics(here::here("img", "asian_youth_excerpt.png"))
```
Trial and error indicated that again dividing the table into multiple screenshots improved the text extraction:

```{r}
asian_sub_2018_A <- image_read(here::here("img", "asian_sub_2018_A.png"))
asian_sub_2018_A <- image_ocr(asian_sub_2018_A)
asian_sub_2018_B <- image_read(here::here("img", "asian_sub_2018_B.png"))
asian_sub_2018_B <- image_ocr(asian_sub_2018_B)
asian_sub_2018 <-str_c(asian_sub_2018_A, asian_sub_2018_B)
```

```{r}
asian_sub_2018 %<>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()

asian_sub_2018
```
Now we need to modify our function a bit for this new data. 

Firstly, we now have colons `:` in our table that we will want to separate by. Unfortunately, eachthe text in each row ins't extracted in the same way by the OCR.  Thus some rows have only a space, while others have a spaces around a colon; or for the row with `VIETNAM` we see a colon followed by a space. Thus we will modify our `seperate()` function with this change. We can specify  that the separator between any letter and any digit should be either a space (`\\s`) or a colon with a space before and after it (`\\s:\\s`) using the or (`|`)opperator. 

So this will look like this:

```{r}
asian_sub_2018 %>%
    separate(., col = value, into = c("Group", "Percent"), sep =  "(?<=[:alpha:])\\s:\\s|\\s(?=[0-9])")

```
Then because of the row with `VIETNAM`, we will want to remove this colon using the `str_remove()` function like this:

```{r, eval = FALSE}
asian_sub_2018 %>%
    separate(., col = value, into = c("Group", "Percent"), sep =  "(?<=[:alpha:])\\s:\\s|\\s(?=[0-9])")%>% 
    mutate(Group= str_remove(string = Group, pattern = ":"))

```

The other difference from the previous function, is that we want to fill in a Race variable with the previous rows. We can do so by first replacing "Men" or "Women" which with the or operator is ("Men|Women"), with "missing". Then we need to convert these to `NA` values using the `na_if()` function of the `dplyr` package, we just need to specify what column to modify and what value to change to `NA`. Finally we will then repace the `NA` values with the previous non-`NA` value using the `fill()` function of the `tidyr` package. Note that this does not work inside of the `mutate()` function. We just need to simply specify what column to modify and then the direction to replace values. In this case we want to replace in the downward direction using the previous values. 

This will look like this:

```{r}

asian_sub_2018 %>%
separate(., col = value, into = c("Group", "Percent"), sep =  "(?<=[:alpha:])\\s:\\s|\\s(?=[0-9])") %>%
mutate(Group= str_remove(string = Group, pattern = ":")) %>%
mutate(Race = str_replace(Group,
                             pattern = "Men|Women", 
                         replacement = "missing"))%>%
  head()

asian_sub_2018 %>%
separate(., col = value, into = c("Group", "Percent"), sep =  "(?<=[:alpha:])\\s:\\s|\\s(?=[0-9])") %>%
mutate(Group= str_remove(string = Group, pattern = ":")) %>%
mutate(Race = str_replace(Group,
                             pattern = "Men|Women", 
                         replacement = "missing")) %>%
    mutate(Race = na_if(Race, "missing")) %>%
  head()

asian_sub_2018 %>%
separate(., col = value, into = c("Group", "Percent"), sep =  "(?<=[:alpha:])\\s:\\s|\\s(?=[0-9])") %>%
mutate(Group= str_remove(string = Group, pattern = ":")) %>%
mutate(Race = str_replace(Group,
                             pattern = "Men|Women", 
                         replacement = "missing")) %>%
    mutate(Race = na_if(Race, "missing")) %>%
    fill(Race, .direction = "down") %>%
  head()

```

OK! Now, let's combine these pieces of our new function with the old pieces:

```{r}

clean_table <- function(table){
  table %>%
    separate(., col = value, into = c("Group", "Percent"), sep =  "(?<=[:alpha:])\\s:\\s|\\s(?=[0-9])") %>% 
    mutate(Group= str_remove(string = Group, pattern = ":")) %>%
    drop_na() %>%
    mutate(Group = str_to_title(Group)) %>%
    mutate(Percent =str_remove(string = Percent, pattern = "\\.")) %>%
    mutate(Percent = as.numeric(Percent)) %>%
    mutate(Percent = Percent * 0.1) %>%
    mutate(Race = str_replace(Group,
                             pattern = "Men|Women", 
                         replacement = "missing")) %>%
    mutate(Race = na_if(Race, "missing")) %>%
    fill(Race, .direction = "down") %>%
    mutate(Gender = str_extract(Group, "Men|Women")) %>%
    mutate(Gender = replace_na(Gender, replace = "All"))
 
}
```


```{r}
asian_sub_2018 <-clean_table(asian_sub_2018)
asian_sub_2018
```

Looking good!


Now we just need to add the data for all Asians from the text. 

```{r, echo = FALSE, out.width="60%"}
knitr::include_graphics(here::here("img", "asian_youth_excerpt.png"))
```

We can do this using the `add_row()` function of the `dplyr()` package.

```{r}
asian_sub_2018 %<>%
  add_row(Group = "Asian_Total",
        Percent = 6.2,
           Race = "Asian Total",
          Gender = "All") %>%
  add_row(Group = "Asian_Total",
        Percent = 6.4,
           Race = "Asian_Total",
          Gender = "Men") %>%
  add_row(Group = "Asian_Total",
        Percent = 6.1,
           Race = "Asian_Total",
          Gender = "Women")

asian_sub_2018
```

OK, now we just want to combine the 2018 data and the 2017 data for the asian subgroups.

First let's add a varaible for year to both. Using `mutate()` we can add a variable `Year` where all values are `2017` like so:

```{r}
asian %<>%
  mutate(Year = 2017)
asian
```

```{r}
asian_sub_2018 %<>%
  mutate(Year = 2018)
asian_sub_2018
```

You may notice that `Gender` is coded differently for the two years. Let's make this consistent now:

```{r}
asian_sub_2018 %>%
  mutate(across(.cols = c(Gender, Group),
                ~str_replace(string = ., 
                            pattern = "Men", 
                        replacement = "Male")),
         across(.cols = c(Gender, Group),
                ~str_replace(string = ., 
                            pattern = "Women", 
                        replacement = "Female")))

```

We can combine these two tibbles using the `bind_rows()` function of `dplyr`.

```{r}

asian_subgroups <- bind_rows(asian, asian_sub_2018)

```

Now we are ready to peform similar wrangling for the Latino subgroups.

### Latino/a Subgroups 2018 

Recall that this was the page with the table of interest for the Latino subgroup 2018 data:

```{r, echo = FALSE, }
knitr::include_graphics(here::here("img", "latino_2018_overview.png"))
```

Trial and error indicated that again dividing the table into multiple screenshots improved the text extraction:

```{r}
latino_a_sub_2018 <- image_read(here::here("img", "latino_a_subgroups_2018.png"))
latino_a_sub_2018 <- image_ocr(latino_a_sub_2018)
latino_a_sub_2018
```

Let's first combine the South and Central American labels. Notice that there are multiple new line expressions in between and we dont see repeated `\n` characters elsewhere.
We can replace the pattern of exactly two `\n` (using `\n{2}` to specify exactly 2) or two newline regex with a space and colon in front with a single space.

```{r}
latino_a_sub_2018 <- str_replace_all(latino_a_sub_2018, pattern = "\\s:\n{2}|\n{2}", replacement = " ")
latino_a_sub_2018 
```


```{r}
latino_a_sub_2018 %<>%
  str_split("\n") %>%
  unlist() %>%
  as_tibble()

latino_a_sub_2018
```


```{r}
latino_a_sub_2018 <-clean_table(latino_a_sub_2018)
latino_a_sub_2018
```


Again we will replace `Pr, Dr, Cuban`:
```{r}
latino_a_sub_2018 %<>%
  mutate(Group = 
           str_replace(string = Group,
                     pattern = "Pr, Dr, Cuban",
                 replacement = "Puerto Rican, Dominican, Cuban"), 
          Race = 
           str_replace(string = Race,
                     pattern = "Pr, Dr, Cuban",
                 replacement = "Puerto Rican, Dominican, Cuban"))

```


And now we will recode gender like before to be consistent:

```{r}
latino_a_sub_2018 %>%
  mutate(across(.cols = c(Gender, Group),
                ~str_replace(string = ., 
                            pattern = "Men", 
                        replacement = "Male")),
         across(.cols = c(Gender, Group),
                ~str_replace(string = ., 
                            pattern = "Women", 
                        replacement = "Female")))

```



Now we just need to combine all the data for the Latino subgroups.


Again, first we will add a year variable to both the 2017 and 2018 data.

```{r}
latino_a %<>%
  mutate(Year = 2017)

latino_a_sub_2018 %<>%
  mutate(Year = 2018)

latino_a_subgroups <- bind_rows(latino_a, latino_a_sub_2018)
latino_a_subgroups
```


### All together

OK, now let's make sure that our notations match across our different tables. For example in the first report the terms male and female where used, but in the second report men and women were used. Let's make this consistent now.

```{r}
dis_long
asian_subgroups
latino_a_subgroups
```


## **Data Analysis**
*** 

**Repeated Cross-sectional Data**

We have pooled (repeated) [cross-sectional](https://en.wikipedia.org/wiki/Cross-sectional_data?oldformat=true) data.

This is data produced from repeated measurement of a [population](https://en.wikipedia.org/wiki/Population?oldformat=true) over time.

It is often infeasible to collect data for an entire population at once. However, we can still obtain meaningful measures using a random [sample](https://en.wikipedia.org/wiki/Sampling_(statistics)?oldformat=true) of the population. 

At specific time-points, data is collected from a sample of the population. The individuals in each sample are not necessarily the same individuals. This separates pooled cross-sectional data from panel data, which is longitudinal data from repeated measurement of the same people.   

By sampling from a population at multiple time points, we can generate population level statistics. Although these statistics have some random error, they can provide insight into how the measure variable is changing in a population over time.

We can accomplish this by plotting the measured values over time. Sometimes, however, the trend isn't exactly clear. Fortunately, there are statistical methods to resolve this issue.

The Mann-Kendall trend test—a variation of the [Kendall rank correlation coefficient](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient?oldformat=true)—tests whether there is a monotonic association, an association that does not increase or decrease but remains static across a dimension.

Recall the youth disconnection rates for Native Americans, some of the highest in the first table we examined. 

```{r}
image_example
```

Let's conduct a Mann-Kendall test for trend.

We can accomplish this with the `Kendall::MannKendall()` function. The `Kendall::MannKendall()` accepts a vector of data for which a trend may be observed. [Consulting the documentation for the `Kendall::MannKendall()` function available on CRAN](https://rdrr.io/cran/Kendall/man/MannKendall.html), we can "test for a a monotonic trend in a time series".



```{r}
dis_long %>%
  filter(Gender == "All",
         Race == "Native American") %>%
  pull(Rate) %>%
  MannKendall(.) %>%
  summary()

```


There does not appear to be a change in the trend. However, it's important to note that we only have `r length(dis_long %>% filter(Gender == "All", Race == "Native American") %>% pull(Rate))` observations.

We can also explore the trend using [simple linear regression](https://en.wikipedia.org/wiki/Simple_linear_regression?oldformat=true). 


```{r}
dis_long %>%
  filter(Gender == "All",
         Race == "Native American") %>%
  lm(Rate ~ Year, data = .) %>%
  summary()
```


For each one year change, the mean increase in disconnection rates is
`r (dis_long%>% filter(Gender == "All", Race == "Native American") %>% lm(Rate ~ Year, data = .))[["coefficients"]]["Year"]`

 This relationship is not statistically significant. Again, we are largely limited by the number of observations in this dataset. 

We can visualize the relationship above.

```{r}
dis_long %>%
  filter(Gender == "All",
         Race == "Native American") %>%
  ggplot(aes(x = Year, y = Rate)) +
  geom_smooth(method = "lm", color = "red") + 
  geom_point() + 
  scale_x_continuous(breaks = seq(2008, 2018, by = 1),
                     labels = seq(2008, 2018, by = 1),
                     limits = c(2008, 2018)) +
  theme_minimal() +
  labs(title = "Youth Disconnection Rates of Native American Youth",
       subtitle = "2008 - 2017",
       x = "Year",
       y = "Disconnection Rate")
```


As we can see, there is a large amount of uncertainty around the fitted line. 

Let's visualize the data! 

## **Data Visualization**
*** 

Let's reproduce the example below.

```{r, out.width = "100%", echo = FALSE, fig.align ="center"}
include_graphics(here::here("img", "Making_the_Connection_plot.png"))
```

We can create a version of the above example with `ggplot` from `tidyverse`.

There are color identifying websites only such as [this](https://imagecolorpicker.com/en/).

Using one of these websites, we identify the [hex triplet](https://en.wikipedia.org/wiki/Web_colors?oldformat=true) for the color used in the visualization included in the PDF: `#008393`. 

```{r}
fa_figurine <- image_read("https://upload.wikimedia.org/wikipedia/commons/7/7c/User_font_awesome.svg")

fa_figurine <- image_fill(fa_figurine,
                          color = "#008393", 
                          point = "+800+800",
                          fuzz = 0)

fa_figurine <- image_fill(fa_figurine,
                          color = "#008393", 
                          point = "+800+1000",
                          fuzz = 0)

plot <-dis_long %>%
   filter(Gender == "All",
          Group != "United States") %>%
  ggplot(aes(x = Year, y = Rate, group=Race)) +
  geom_line(color = "#008393", size = 0.5) +
  geom_point(color = "#008393", size = 3) +
  scale_x_continuous(breaks = seq(2008,2018, by=1),
                     limits = c(2008,2018)) +
  scale_y_continuous(breaks = seq(5,30, by =5),
                     limits = c(5,30)) +
  draw_image(fa_figurine, x = 2017, y = 23.5, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 17.5, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 13, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 9, scale = 2) +
  draw_image(fa_figurine, x = 2017, y = 6.5, scale = 2) +
  labs(title = "FIGURE 1 YOUTH DISCONNECTION BY RACE AND ETHNICITY, 2008 - 2017",
       y = "YOUTH DISCONNECTION (%)") +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank())

plot
```


We can build off of this idea, using a custom color palette to create a gradient based off the color used. 


```{r}
custom_pal <- colorRampPalette(c("white", "#008393"))
gender_n <- 3

asian_total <- asian_subgroups%>%
  filter(Year == 2017,
       Gender == "All",
         Race == "Asian") %>%
  pull(Percent)

asian_subgroups %>%
  filter(Year == 2017) %>%
  complete(Gender, Race) %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Percent, ties.method = "min")) %>%
  group_by(Race) %>%
  mutate(rank_all = sub_rank[Gender == "All"]) %>%
  ungroup() %>%
  mutate(Race = fct_reorder(Race, rank_all)) %>%
  ggplot(aes(x = Race, y = Percent, fill = Gender)) +
  geom_hline(yintercept = asian_total, 
             color = "black",
             linetype = 2) + 
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY ASIAN SUBGROUP, 2017",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,20,2),
                     labels = seq(0,20,2),
                     limits = c(0,20)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  annotate("text", label = 'bold("ASIAN TOTAL")',
           color = "#008393", 
           size = 3,
           x = 1.2,
           y = asian_total + 1,
           parse = TRUE)
```


From the above plot, it becomes apparent that the Hmong subgroup produces a small proportion of the total number of asian disconnected youth. The Asian total youth disconnection rate is more alike the youth disconnection rates for all other subgroups than the Hmong youth disconnection rate.

We can confirm this by revisiting the table.

avocado - update:

```{r, eval = FALSE}
image2
```

The Hmong group represents `r round((8300*100)/145600)`% of all Asian disconnected youth. 

This shows the importance of adding small details such as the composite line to plots. It helps provide a simple yet nuanced picture of what is going on. 

Lastly, we can add annotations to add provide even more depth to the visualization. 

```{r}
latino_a_total <- latino_a_subgroups %>%
  filter(Year == 2017) %>%
  filter(Gender == "All",
         Race == "Latino") %>%
  pull(Percent)

latino_a_subgroups %>%
  filter(Year == 2017) %>%
  complete(Gender, Race) %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Percent, ties.method = "min")) %>%
  group_by(Race) %>%
  mutate(rank_all = sub_rank[Gender == "All"]) %>%
  ungroup() %>%
  mutate(Race = fct_reorder(Race, rank_all)) %>%
  ggplot(aes(x = Race, y = Percent, fill = Gender)) +
  geom_hline(yintercept = latino_a_total, 
             color = "black",
             linetype = 2) + 
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY LATINO/A SUBGROUP, 2017",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,20,2),
                     labels = seq(0,20,2),
                     limits = c(0,20)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  annotate("text", label = 'bold("LATINO TOTAL")',
           color = "#008393", 
           size = 3,
           x = 1.2,
           y = latino_a_total + 1,
           parse = TRUE)
```

```{r, eval = FALSE}
asian_subgroups %>%
  complete(Gender, Subgroup, Year) %>%
  group_by(Subgroup) %>%
  mutate(missing = sum(is.na(Rate))) %>%
  filter(missing == 0) %>%
  dplyr::select(-missing) %>%
  ungroup() %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Rate, ties.method = "min")) %>%
  group_by(Subgroup, Year) %>%
  mutate(rank_all = sub_rank[Gender == "ALL"]) %>%
  ungroup() %>%
  group_by(Year) %>%
  mutate(threshold = Rate[Gender == "ALL" & Subgroup == "ALL"]) %>%
  ungroup() %>%
  mutate(Subgroup = fct_reorder(Subgroup, rank_all)) %>%
  ggplot(aes(x = Subgroup, y = Rate, fill = Gender)) +
  facet_wrap(Year ~., ncol = 1) +
  geom_hline(aes(yintercept = threshold), linetype = 2) +
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY ASIAN SUBGROUP, 2017-2018",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,10,2),
                     labels = seq(0,10,2),
                     limits = c(0,10)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r, eval = FALSE}
df3 %>%
  complete(Gender, Subgroup, Year) %>%
  group_by(Subgroup) %>%
  mutate(missing = sum(is.na(Rate))) %>%
  filter(missing == 0) %>%
  dplyr::select(-missing) %>%
  ungroup() %>%
  group_by(Gender) %>%
  mutate(sub_rank = rank(Rate, ties.method = "min")) %>%
  group_by(Subgroup, Year) %>%
  mutate(rank_all = sub_rank[Gender == "ALL"]) %>%
  ungroup() %>%
  group_by(Year) %>%
  mutate(threshold = Rate[Gender == "ALL" & Subgroup == "ALL"]) %>%
  ungroup() %>%
  mutate(Subgroup = fct_reorder(Subgroup, rank_all)) %>%
  ggplot(aes(x = Subgroup, y = Rate, fill = Gender)) +
  facet_wrap(Year ~., ncol = 1) +
  geom_hline(aes(yintercept = threshold), linetype = 2) +
  geom_bar(stat = "identity",
           color = "transparent",
           size = 0.5,
           position = "dodge",
           width = 0.5) +
  labs(title = "FIGURE X YOUTH DISCONNECTION BY LATINO/A SUBGROUP, 2017",
       subtitle = "ORDERED BY OVERALL DISCONNECTION",
       y = "YOUTH DISCONNECTION (%)",
       fill = "Gender") +
  scale_fill_manual(values = rev(custom_pal(gender_n + 1))) +
  scale_y_continuous(breaks = seq(0,20,2),
                     labels = seq(0,20,2),
                     limits = c(0,20)) +
  theme_classic() +
  theme(title = element_text(size = 10,
                             color = "#008393",
                             face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1))
```

## **Summary**
*** 

## **Suggested Homework**
*** 

1) Find another table in the document. Find differences between groups with the process described above. 

## **Helpful Links**
*** 


avocado*This concepts listed here must be revisited.*


<u>Terms and concepts covered:</u>  

[Tidyverse](https://www.tidyverse.org/){target="_blank"}  
[RStudio cheatsheets](https://rstudio.com/resources/cheatsheets/){target="_blank"}  
[Inference](https://www.britannica.com/science/inference-statistics){target="_blank"}  
[Regression](https://lindeloev.github.io/tests-as-linear/){target="_blank"}  
[Different types of regression](https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/){target="_blank"}  
[Ordinary least squares method](http://setosa.io/ev/ordinary-least-squares-regression/){target="_blank"}  
[Residual](https://www.statisticshowto.datasciencecentral.com/residual/){target="_blank"}  

<u>Packages used in this case study: </u>

 Package   | Use                                                                         
---------- |-------------
[**here**](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data
[**tidyverse**](https://readr.tidyverse.org/){target="_blank"}      | for data science operations
[**pdftools**](https://readr.tidyverse.org/){target="_blank"}      | to manage PDF documents
[**magick**](https://cran.r-project.org/web/packages/magick/vignettes/intro.html#Kernel_convolution){target="_blank"}      | for image processing 

## Acknowledgements

We would like to acknowledge [Tamar Mendelson](https://www.jhsph.edu/faculty/directory/profile/1770/tamar-mendelson) for assisting in framing the major direction of the case study.

We would also like to acknowledge the [Bloomberg American Health Initiative](https://americanhealth.jhu.edu/) for funding this work. 